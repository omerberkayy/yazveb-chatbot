import os
from dotenv import load_dotenv
import gradio as gr

#langChain bileÅŸenleri
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate

#.env'den ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()

#model ve embeddin seÃ§imi yapÄ±lÄ±p, ayarlarÄ± eklendi

os.environ["GOOGLE_API_KEY"] = os.getenv("GOOGLE_API_KEY")

llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-base")


DATA_PATH = "data/raw"
CHROMA_PATH = "data/processed/chroma_db"

#chroma db baÅŸlatÄ±ldÄ±
vector_store = Chroma(
    collection_name="community_knowledge",
    embedding_function=embeddings,
    persist_directory=CHROMA_PATH,
)

#eÄŸer chroma boÅŸsa veriyi yÃ¼kle, parÃ§alara (chunk) ayÄ±r ve chroma'ya ekle
def initialize_database():
    if len(vector_store.get()["ids"]) == 0:
        print("âš™ï¸  VeritabanÄ± boÅŸ, embedding iÅŸlemi baÅŸlatÄ±lÄ±yor...")

        docs = []
        for filename in os.listdir(DATA_PATH):
            if filename.endswith(".txt"): #dosya uzantÄ±sÄ± .txt olmayan dosyalarÄ± atla
                with open(os.path.join(DATA_PATH, filename), "r", encoding="utf-8") as f:
                    text = f.read().strip()
                    docs.append({"content": text, "source": filename})
        #chunk_size ve chunk_over ayarÄ± veri setine gÃ¶re ayarlandÄ±
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=100,
            separators=["\n## ", "\n# ", "\n", " "] #veri setinde baÅŸlÄ±klar markdown ile ayrÄ±ldÄ±
        )

        chunks = []
        for doc in docs:
            splits = text_splitter.split_text(doc["content"])
            for chunk in splits:
                chunks.append({
                    "text": chunk,
                    "source": doc["source"]
                })
        #parÃ§a listesi langchain formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼
        all_splits = [
            Document(page_content=chunk["text"], metadata={"source": chunk["source"]})
            for chunk in chunks
        ]
        #huggingface modeli kullanÄ±larak, veriler vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼ ve chroma db'ye eklendi
        vector_store.add_documents(all_splits)
        vector_store.persist()
        print(f"âœ… {len(all_splits)} belge eklendi ve Chroma kaydedildi.")
    else:
        print("âœ… Mevcut Chroma DB yÃ¼klendi.")


#veri setine uygun geliÅŸmiÅŸ bir prompt eklendi
prompt_template = ChatPromptTemplate.from_template("""
Sen, bir Ã¶ÄŸrenci topluluÄŸu asistanÄ±sÄ±n. GÃ¶revin, topluluk hakkÄ±nda sorulan sorulara
Ã¶nceden kaydedilmiÅŸ bilgilerden yararlanarak net, samimi ve doÄŸru yanÄ±tlar vermektir.

AÅŸaÄŸÄ±da topluluk hakkÄ±nda bilgiler, geÃ§miÅŸ etkinlikler ve iletiÅŸim detaylarÄ± yer almaktadÄ±r.
KullanÄ±cÄ± bir soru sorduÄŸunda:
- Sorunun hangi kategoriye ait olduÄŸunu (etkinlik, genel bilgi, iletiÅŸim vb.) anlamaya Ã§alÄ±ÅŸ.
- BaÄŸlama en uygun yanÄ±tÄ± kÄ±sa, doÄŸal ve aÃ§Ä±klayÄ±cÄ± bir ÅŸekilde oluÅŸtur.
- EÄŸer bilgi mevcut deÄŸilse, â€œBu konuda elimde bilgi bulunmuyor.â€ gibi kibar bir yanÄ±t ver.

Topluluk Bilgileri ve Etkinlik KayÄ±tlarÄ±:
{context}

KullanÄ±cÄ± Sorusu: {question}

Asistan YanÄ±tÄ±:
""")

#kullanÄ±cÄ±nÄ±n sorusuna gÃ¶re en alakalÄ± 3 sonuÃ§ chroma db'den getirilip, llm'in cevap Ã¼retmesi saÄŸlandÄ±
def chatbot_interface(user_query):
    if not user_query.strip():
        return "LÃ¼tfen bir soru giriniz."

    retrieved_docs = vector_store.similarity_search(user_query, k=3)
    context_text = "\n\n".join([doc.page_content for doc in retrieved_docs])

    prompt = prompt_template.format(context=context_text, question=user_query)
    response = llm.invoke(prompt)
    return response.content


#chatbota arayÃ¼z eklemek iÃ§in python'Ä±n gradio kÃ¼tÃ¼phanesi kullanÄ±ldÄ±
def launch_app():
    initialize_database()

    with gr.Blocks() as demo:
        gr.Markdown("## ğŸ¤– Topluluk Chatbot (RAG + Gemini)")
        gr.Markdown("Topluluk hakkÄ±nda sorularÄ±nÄ±zÄ± aÅŸaÄŸÄ±ya yazabilirsiniz ğŸ‘‡")

        user_input = gr.Textbox(label="Sorunuzu yazÄ±n:", placeholder="Ã–rnek: TopluluÄŸa nasÄ±l katÄ±labilirim?")
        output = gr.Textbox(label="Asistan YanÄ±tÄ±", lines=6)
        submit_btn = gr.Button("GÃ¶nder")

        submit_btn.click(fn=chatbot_interface, inputs=user_input, outputs=output)

    demo.launch(server_name="0.0.0.0", server_port=7860)


if __name__ == "__main__":
    launch_app()

